import requests

# ======================
# 1. é…ç½®
# ======================
KEYWORDS = ['èç‰‡', 'é‡‡é›†', '.spider']  # æ‚¨è¦æœç´¢çš„ 3 ä¸ªå…³é”®è¯
ALL_RAW_URLS = []

# ======================
# 2. æœç´¢æ¯ä¸ªå…³é”®è¯ï¼Œè·å– Raw URL
# ======================
def search_github(keyword):
    print(f"ğŸ” æœç´¢å…³é”®è¯: {keyword}")
    url = f'https://api.github.com/search/code?q={keyword}+in:file&per_page=100'

    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()

        items = data.get('items', [])
        print(f"âœ… æ‰¾åˆ° {len(items)} ä¸ªåŒ…å« '{keyword}' çš„æ–‡ä»¶")

        for item in items:
            try:
                raw_url = item.get('download_url')
                if raw_url:
                    ALL_RAW_URLS.append(raw_url)
            except Exception as e:
                print(f"âš ï¸ è§£ææ–‡ä»¶å‡ºé”™: {e}")

    except requests.exceptions.RequestException as e:
        print(f"âŒ æœç´¢å…³é”®è¯ '{keyword}' å¤±è´¥: {e}")

# ======================
# 3. ä¸»å‡½æ•°ï¼šæ±‡æ€»å¹¶å»é‡
# ======================
def main():
    for keyword in KEYWORDS:
        search_github(keyword)

    # å»é‡
    unique_raw_urls = list(set(ALL_RAW_URLS))
    print(f"\nğŸ”¢ æ€»å…±æ‰¾åˆ° {len(unique_raw_urls)} ä¸ªå”¯ä¸€ Raw URL")

    # ä¿å­˜åˆ°æ–‡ä»¶
    output_filename = 'tvbox_raw_sources.txt'
    with open(output_filename, 'w', encoding='utf-8') as f:
        for url in unique_raw_urls:
            f.write(url + '\n')

    print(f"âœ… Raw URL å·²ä¿å­˜åˆ°æ–‡ä»¶: {output_filename}")

if __name__ == '__main__':
    main()
