import requests

# ======================
# 1. é…ç½®
# ======================
KEYWORDS = ['èç‰‡', 'é‡‡é›†', '.spider']  # æ‚¨è¦æœç´¢çš„ 3 ä¸ªå…³é”®è¯
OUTPUT_FILE = 'tvbox_raw_sources.txt'  # æœ€ç»ˆè¾“å‡ºçš„æ–‡ä»¶åï¼ˆä¼šä¿å­˜åœ¨ merge/ ç›®å½•ä¸‹ï¼‰

# ======================
# 2. æœç´¢å¹¶æå– Raw URL
# ======================
def main():
    all_raw_urls = []

    for keyword in KEYWORDS:
        print(f"ğŸ” æ­£åœ¨æœç´¢å…³é”®è¯: {keyword}")
        url = f'https://api.github.com/search/code?q={keyword}+in:file&per_page=100'

        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()

            items = data.get('items', [])
            print(f"âœ… æ‰¾åˆ° {len(items)} ä¸ªåŒ…å« '{keyword}' çš„æ–‡ä»¶")

            for item in items:
                try:
                    raw_url = item.get('download_url')
                    if raw_url:
                        all_raw_urls.append(raw_url)
                except Exception as e:
                    print(f"âš ï¸ è§£ææ–‡ä»¶å‡ºé”™: {e}")

        except requests.exceptions.RequestException as e:
            print(f"âŒ æœç´¢å…³é”®è¯ '{keyword}' å¤±è´¥: {e}")

    # å»é‡
    unique_raw_urls = list(set(all_raw_urls))
    print(f"ğŸ”¢ æ€»å…±æ‰¾åˆ° {len(unique_raw_urls)} ä¸ªå”¯ä¸€ Raw URL")

    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        for url in unique_raw_urls:
            f.write(url + '\n')

    print(f"âœ… Raw URL å·²ä¿å­˜åˆ°æ–‡ä»¶: {OUTPUT_FILE}")

if __name__ == '__main__':
    main()
